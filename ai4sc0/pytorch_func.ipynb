{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchÁöÑÂáΩÊï∞ÂèòÊç¢\n",
    "\n",
    "\n",
    "‰∏ãÈù¢‰ªãÁªç‰∏Ä‰∏ãÁî±torch.funcÊèê‰æõÁöÑÂáΩÊï∞ÂèòÊç¢ÂäüËÉΩÔºåËøôÂú®‰ΩøÁî®PyTorchÂÅöÁßëÂ≠¶ËÆ°ÁÆóÊó∂Â∞§‰∏∫ÊúâÁî®„ÄÇÊàë‰ª¨‰∏ãÈù¢Â±ïÁ§∫‰∏Ä‰∫õÂÆÉÁöÑ‰æãÂ≠ê„ÄÇ\n",
    "\n",
    "## Ëá™Âä®ÂêëÈáèÂåñÂπ∂Ë°å\n",
    "\n",
    "‰∏ãÈù¢Êàë‰ª¨ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞ÔºåËøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÂØπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:50.382326Z",
     "start_time": "2023-04-14T07:33:50.377880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 4., 6.],\n",
      "        [3., 6., 9.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 2.,  4.,  6.],\n",
      "         [ 3.,  6.,  9.]],\n",
      "\n",
      "        [[ 4.,  8., 12.],\n",
      "         [ 8., 16., 24.],\n",
      "         [12., 24., 36.]],\n",
      "\n",
      "        [[ 9., 18., 27.],\n",
      "         [18., 36., 54.],\n",
      "         [27., 54., 81.]]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [2., 4., 6.],\n",
      "        [3., 6., 9.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 2.,  4.,  6.],\n",
      "         [ 3.,  6.,  9.]],\n",
      "\n",
      "        [[ 4.,  8., 12.],\n",
      "         [ 8., 16., 24.],\n",
      "         [12., 24., 36.]],\n",
      "\n",
      "        [[ 9., 18., 27.],\n",
      "         [18., 36., 54.],\n",
      "         [27., 54., 81.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.func import vmap\n",
    "\n",
    "def f(x):\n",
    "    return torch.outer(x,x)\n",
    "\n",
    "x=torch.arange(1.,4.)\n",
    "print(f(x))\n",
    "bx=vmap(f)(f(x))\n",
    "print(bx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ëøô‰∏™‰æãÂ≠êÂèØËÉΩËøá‰∫éÁÆÄÂçïÔºåÊòæÁ§∫‰∏çÂá∫Êù•Ëøô‰∏™ÂáΩÊï∞ÁöÑÂ®ÅÂäõ„ÄÇ‰ΩÜÊòØÂØπ‰∫éPyTorchÂÜôÊàêÁöÑÂá†‰πéÊâÄÊúâÂáΩÊï∞ÔºåÈÉΩÂèØ‰ª•Ëøô‰πàÂÅöÔºåÂåÖÊã¨Â§çÊùÇÁöÑÊ±ÇËß£Âô®Ôºå‰æãÂ¶ÇÊàë‰ª¨ÂÜôÁöÑRTEÊ±ÇËß£Âô®„ÄÇ‰æãÂ¶Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.124633Z",
     "start_time": "2023-04-14T07:33:50.384656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 50, 400]) torch.Size([4, 50, 400]) torch.Size([4, 1, 400])\n",
      "torch.Size([4, 50, 400]) torch.Size([4, 50, 400]) torch.Size([4, 1, 400])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_gauss_point(n):\n",
    "    x, w = np.polynomial.legendre.leggauss(n)\n",
    "    return torch.from_numpy(x).to(dtype=torch.get_default_dtype()), torch.from_numpy(w).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "a = 1\n",
    "c = 1\n",
    "rho = 1\n",
    "cv = 1\n",
    "\n",
    "# spatial grid\n",
    "N = 400\n",
    "L = 1\n",
    "dx = L / N\n",
    "x = torch.arange(0.5 * dx, L + 0.5 * dx, dx)\n",
    "\n",
    "Tini =  vmap(lambda cas:(1 + 0.1 * torch.sin(2 * math.pi * x+torch.sin(cas)))*(1+torch.sin(cas)))(torch.tensor([1,2,3,4]))\n",
    "sigma = vmap(lambda cas:(1 + 0.1 * torch.sin(2 * math.pi * x+torch.sin(cas+1)))*(1+torch.sin(cas)))(torch.tensor([1,2,3,4]))\n",
    "    \n",
    "def solve(Tini,sigma):\n",
    "    CFL = 0.8\n",
    "    dt = CFL * dx  # time step\n",
    "    dtc = dt * c\n",
    "    ddtc = 1 / dtc\n",
    "\n",
    "    datarecord_sigma=sigma.clone()[None,:]\n",
    "    \n",
    "    # velocity grid & angle\n",
    "    Nvx = 8\n",
    "    mu, wmu = get_gauss_point(Nvx)\n",
    "\n",
    "    # distribution function\n",
    "    T = Tini\n",
    "    I = 0.5 * a * c * Tini**4\n",
    "    I = I.repeat(Nvx, 1)\n",
    "    I = F.pad(I[None, ...], (1, 1), mode='circular')[0]\n",
    "    I0 = wmu @ I  # energe\n",
    "    sigma = sigma.repeat(Nvx // 2, 1)\n",
    "\n",
    "    t=1.0\n",
    "    Nt=int(t / dt)\n",
    "    list_T=[]\n",
    "    list_E=[]\n",
    "    for loop in range(Nt):  #=1: 1/dt\n",
    "        I_out = I.clone()\n",
    "        T_out = T.clone()\n",
    "        I0_out = I0.clone()\n",
    "\n",
    "        index = slice(1, -1)\n",
    "        index_add1 = slice(2, None)\n",
    "        index_sub1 = slice(None, -2)\n",
    "\n",
    "        # streaming, positive vx\n",
    "        lv = slice(Nvx // 2, None)\n",
    "        coe = mu[lv]\n",
    "        I[lv, index] = I_out[lv, index] - dt / dx * coe[..., None] * (\n",
    "            I_out[lv, index] - I_out[lv, index_sub1]) + dt * sigma * (\n",
    "                (0.5 * a * c * T_out**4).repeat(Nvx // 2, 1) - I_out[lv, index])\n",
    "        \n",
    "        # streaming, negative vx\n",
    "        lv = slice(0, Nvx // 2)\n",
    "        coe = mu[lv]\n",
    "        I[lv, index] = I_out[lv, index] - dt / dx * coe[..., None] * (\n",
    "            I_out[lv, index_add1] - I_out[lv, index]) + dt * sigma * (\n",
    "                (0.5 * a * c * T_out**4).repeat(Nvx // 2, 1) - I_out[lv, index])\n",
    "\n",
    "        I = F.pad(I[None, ..., 1:-1], (1, 1), mode='circular')[0]\n",
    "        T = T_out + dt / cv * sigma[0, :] * (I0_out[index] - a * c * T_out**4)\n",
    "        I0 = wmu @ I\n",
    "\n",
    "        if loop%10==0:\n",
    "            list_E.append(I0[...,1:-1].clone())\n",
    "            list_T.append(T.clone())\n",
    "    datarecord_E=torch.stack(list_E,dim=0)\n",
    "    datarecord_T=torch.stack(list_T,dim=0)\n",
    "    return datarecord_E,datarecord_T,datarecord_sigma\n",
    "\n",
    "E,T,sigma=vmap(solve)(Tini,sigma)\n",
    "print(E.shape,T.shape,sigma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ëá™Âä®Ê±ÇÂØº\n",
    "\n",
    "ÊúÄÁÆÄÂçïÁöÑÂ∞±ÊòØ‰ΩøÁî®gradÊ±ÇÂáΩÊï∞ÂØºÊï∞ÔºåÂÆÉÂÅáËÆæÂáΩÊï∞ËøîÂõûÁöÑÊòØ‰∏Ä‰∏™ÂÄºÔºåÁÑ∂ÂêéÊ±ÇËøô‰∏™ÂÄºÂØπ‰∫éËæìÂÖ•ÁöÑÂØºÊï∞„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.132848Z",
     "start_time": "2023-04-14T07:33:51.126517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9999), tensor(0.9999))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9999), tensor(0.9999))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.func import grad\n",
    "x = torch.randn([]) #ÂèØ‰ª•ËØïËØïÊîπÂΩ¢Áä∂‰ºöÂèëÁîü‰ªÄ‰πà\n",
    "fx = lambda x: torch.sin(x)\n",
    "cos_x = grad(fx)(x)\n",
    "\n",
    "torch.cos(x),cos_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¶ÇÊûúËæìÂá∫ÁöÑ‰∏çÊòØ‰∏Ä‰∏™ÂÄºÔºåÈÇ£‰πàgradÊñπÊ≥ïÂ∞±‰∏çÂÜçËµ∑‰ΩúÁî®‰∫Ü„ÄÇËøôÊó∂ÔºåÊ†πÊçÆÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÂØºÊï∞‰∏çÂêåÔºåÊúâÂ§öÁßç‰∏çÂêåÁöÑÂÅöÊ≥ï„ÄÇ‰æãÂ¶ÇÂØπ‰∫ésinËøô‰∏™‰æãÂ≠êÔºåÂÅáËÆæËæìÂÖ•ÁöÑÊòØ‰∏Ä‰∏™ÂêëÈáèÔºåÊàë‰ª¨ÂÖ∂ÂÆûÂè™ÊÉ≥Ê±ÇËæìÂá∫ÁöÑÊØè‰∏™ÂÄºÂØπÂ∫îËæìÂÖ•ÁöÑÊØè‰∏™ÂÄºÁöÑÂØºÔºåÂ∞±ÂèØ‰ª•Áî®vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.150944Z",
     "start_time": "2023-04-14T07:33:51.134537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]),\n",
       " tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]),\n",
       " tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([10,]) #ÂèØ‰ª•ËØïËØïÊîπÂΩ¢Áä∂‰ºöÂèëÁîü‰ªÄ‰πà\n",
    "fx=lambda x: torch.sin(x)\n",
    "cos_x = vmap(grad(fx))(x) #gradÂáΩÊï∞Ë¢´ÂêëÈáèÂåñÂà∞‰∫Ü‰∏Ä‰∏™vector‰∏ä\n",
    "\n",
    "torch.cos(x),cos_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËøòÊúâ‰∏ÄÁßçÊÉÖÂÜµÔºåÂ∞±ÊòØÊàë‰ª¨ÊÉ≥Ë¶ÅÊ±ÇÁöÑÂ∞±ÊòØËæìÂá∫ÁöÑÊØè‰∏™ÂÄºÂØπËæìÂÖ•ÁöÑÊØè‰∏™ÂÄºÁöÑÂØºÊï∞ÔºåÊ≠§Êó∂Êàë‰ª¨Áõ∏Ê±ÇÁöÑÊòØjacobianÁü©Èòµ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.165143Z",
     "start_time": "2023-04-14T07:33:51.153503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([10]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9992,  0.7487,  0.9434,  0.9032,  0.9164,  0.6165,  0.5111,  1.0000,\n",
       "          0.7079, -0.1347]),\n",
       " tensor([[ 0.9992,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.7487,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.9434,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.9032,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9164,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6165,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5111,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.7079, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.1347]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([10]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9992,  0.7487,  0.9434,  0.9032,  0.9164,  0.6165,  0.5111,  1.0000,\n",
       "          0.7079, -0.1347]),\n",
       " tensor([[ 0.9992,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.7487,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.9434,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.9032,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9164,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6165,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5111,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.7079, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.1347]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.func import jacrev,jacfwd,hessian\n",
    "\n",
    "x = torch.randn([10,]) #ÂèØ‰ª•ËØïËØïÊîπÂΩ¢Áä∂‰ºöÂèëÁîü‰ªÄ‰πà\n",
    "fx=lambda x: torch.sin(x)\n",
    "cos_x = jacrev(fx)(x) #gradÂáΩÊï∞Ë¢´ÂêëÈáèÂåñÂà∞‰∫Ü‰∏Ä‰∏™vector‰∏ä\n",
    "\n",
    "print(cos_x.shape,x.shape,fx(x).shape)\n",
    "torch.cos(x),cos_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.199268Z",
     "start_time": "2023-04-14T07:33:51.167656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 10, 2, 10, 2]) torch.Size([10, 2])\n",
      "torch.Size([10, 2, 10, 2, 10, 2]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.func import jacrev,jacfwd,hessian\n",
    "\n",
    "x = torch.randn([10,2]) #ÂèØ‰ª•ËØïËØïÊîπÂΩ¢Áä∂‰ºöÂèëÁîü‰ªÄ‰πà\n",
    "fx=lambda x: torch.sin(x)\n",
    "hessian_x = hessian(fx)(x) #gradÂáΩÊï∞Ë¢´ÂêëÈáèÂåñÂà∞‰∫Ü‰∏Ä‰∏™vector‰∏ä\n",
    "\n",
    "print(hessian_x.shape,x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Êõ¥‰∏∫Â∏∏ËßÅÁöÑÊÉÖÂÜµÊòØ‰ª•‰∏ä‰∏§ÁßçÁöÑÊ∑∑ÂêàÔºå‰æãÂ¶ÇÔºåÊàë‰ª¨Áî®‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÂéªÊãüÂêà‰∫åÁª¥ÁöÑEulerÊñπÁ®ãÁöÑËß£ÔºåËøô‰∏™ÁΩëÁªúÊòØ‰ªéÂêëÈáèÂà∞ÂêëÈáèÁöÑ‰∏Ä‰∏™Êò†Â∞ÑÔºåÊàë‰ª¨Â∏åÊúõËÆ°ÁÆóÂæóÂà∞$\\frac{\\partial f}{\\partial (x,t)}$ËøôÊ†∑‰∏Ä‰∏™Êúâ6‰∏™ÂÖÉÁ¥†ÁöÑjacobian„ÄÇÂêåÊó∂Êàë‰ª¨ÁΩëÁªúÁöÑËæìÂÖ•ÊòØbatchsize=1000ÔºåÊàë‰ª¨Â∞±Ë¶ÅÂêåÊó∂ËÆ°ÁÆóËøô1000‰∏™sampleÁöÑjacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.262010Z",
     "start_time": "2023-04-14T07:33:51.201449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([1000, 2]),y.shape=torch.Size([1000, 3]),y2.shape=torch.Size([1000, 3])\n",
      "dy_dx_1.shape=torch.Size([1000, 3, 2]),dy_dx_2.shape=torch.Size([1000, 3, 2])\n",
      "ddy_dxx.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx2.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx3.shape=torch.Size([1000, 3, 2, 2])\n",
      "x.shape=torch.Size([1000, 2]),y.shape=torch.Size([1000, 3]),y2.shape=torch.Size([1000, 3])\n",
      "dy_dx_1.shape=torch.Size([1000, 3, 2]),dy_dx_2.shape=torch.Size([1000, 3, 2])\n",
      "ddy_dxx.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx2.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx3.shape=torch.Size([1000, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn([1000,2])\n",
    "Net=torch.nn.Linear(2,3)\n",
    "y=Net(x)\n",
    "y2=vmap(Net)(x)\n",
    "print(f\"{x.shape=},{y.shape=},{y2.shape=}\")\n",
    "\n",
    "dy_dx_1=vmap(jacrev(Net))(x)\n",
    "dy_dx_2=vmap(jacfwd(Net))(x)\n",
    "print(f\"{dy_dx_1.shape=},{dy_dx_2.shape=}\")\n",
    "\n",
    "def myhessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "def myhessian2(f):\n",
    "    return jacrev(jacfwd(f))\n",
    "\n",
    "ddy_dxx=vmap(hessian(Net))(x)\n",
    "ddy_dxx2=vmap(myhessian(Net))(x)\n",
    "ddy_dxx3=vmap(myhessian2(Net))(x)\n",
    "\n",
    "print(f\"{ddy_dxx.shape=},{ddy_dxx2.shape=},{ddy_dxx3.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Â¶Ç‰ΩïÈÄâÊã©jacrev‰∏éjacfwd\n",
    "\n",
    "\n",
    "jacrev‰∏éjacfwd\n",
    "> These two functions compute the same values (up to machine numerics), but differ in their implementation: jacfwd uses forward-mode automatic differentiation, which is more efficient for ‚Äútall‚Äù Jacobian matrices, while jacrev uses reverse-mode, which is more efficient for ‚Äúwide‚Äù Jacobian matrices. For matrices that are near-square, jacfwd probably has an edge over jacrev.\n",
    "\n",
    "‰ª•ÂèäÂØπ‰∫éhessian\n",
    "\n",
    "> To implement hessian, we could have used jacfwd(jacrev(f)) or jacrev(jacfwd(f)) or any other composition of the two. But forward-over-reverse is typically the most efficient. That‚Äôs because in the inner Jacobian computation we‚Äôre often differentiating a function wide Jacobian (maybe like a loss function ùëì:‚Ñù‚Åø‚Üí‚Ñù), while in the outer Jacobian computation we‚Äôre differentiating a function with a square Jacobian (since ‚àáùëì:‚Ñù‚Åø‚Üí‚Ñù‚Åø), which is where forward-mode wins out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More \n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/per_sample_grads.html\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/jacobians_hessians.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
