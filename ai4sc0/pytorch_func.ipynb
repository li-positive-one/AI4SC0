{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchçš„å‡½æ•°å˜æ¢\n",
    "\n",
    "\n",
    "ä¸‹é¢ä»‹ç»ä¸€ä¸‹ç”±torch.funcæä¾›çš„å‡½æ•°å˜æ¢åŠŸèƒ½ï¼Œè¿™åœ¨ä½¿ç”¨PyTorchåšç§‘å­¦è®¡ç®—æ—¶å°¤ä¸ºæœ‰ç”¨ã€‚æˆ‘ä»¬ä¸‹é¢å±•ç¤ºä¸€äº›å®ƒçš„ä¾‹å­ã€‚\n",
    "\n",
    "## è‡ªåŠ¨å‘é‡åŒ–å¹¶è¡Œ\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯å¯¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:50.382326Z",
     "start_time": "2023-04-14T07:33:50.377880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 4., 6.],\n",
      "        [3., 6., 9.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 2.,  4.,  6.],\n",
      "         [ 3.,  6.,  9.]],\n",
      "\n",
      "        [[ 4.,  8., 12.],\n",
      "         [ 8., 16., 24.],\n",
      "         [12., 24., 36.]],\n",
      "\n",
      "        [[ 9., 18., 27.],\n",
      "         [18., 36., 54.],\n",
      "         [27., 54., 81.]]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [2., 4., 6.],\n",
      "        [3., 6., 9.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 2.,  4.,  6.],\n",
      "         [ 3.,  6.,  9.]],\n",
      "\n",
      "        [[ 4.,  8., 12.],\n",
      "         [ 8., 16., 24.],\n",
      "         [12., 24., 36.]],\n",
      "\n",
      "        [[ 9., 18., 27.],\n",
      "         [18., 36., 54.],\n",
      "         [27., 54., 81.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.func import vmap\n",
    "\n",
    "def f(x):\n",
    "    return torch.outer(x,x)\n",
    "\n",
    "x=torch.arange(1.,4.)\n",
    "print(f(x))\n",
    "bx=vmap(f)(f(x))\n",
    "print(bx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ä¸ªä¾‹å­å¯èƒ½è¿‡äºç®€å•ï¼Œæ˜¾ç¤ºä¸å‡ºæ¥è¿™ä¸ªå‡½æ•°çš„å¨åŠ›ã€‚ä½†æ˜¯å¯¹äºPyTorchå†™æˆçš„å‡ ä¹æ‰€æœ‰å‡½æ•°ï¼Œéƒ½å¯ä»¥è¿™ä¹ˆåšï¼ŒåŒ…æ‹¬å¤æ‚çš„æ±‚è§£å™¨ï¼Œä¾‹å¦‚æˆ‘ä»¬å†™çš„RTEæ±‚è§£å™¨ã€‚ä¾‹å¦‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.124633Z",
     "start_time": "2023-04-14T07:33:50.384656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 50, 400]) torch.Size([4, 50, 400]) torch.Size([4, 1, 400])\n",
      "torch.Size([4, 50, 400]) torch.Size([4, 50, 400]) torch.Size([4, 1, 400])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_gauss_point(n):\n",
    "    x, w = np.polynomial.legendre.leggauss(n)\n",
    "    return torch.from_numpy(x).to(dtype=torch.get_default_dtype()), torch.from_numpy(w).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "a = 1\n",
    "c = 1\n",
    "rho = 1\n",
    "cv = 1\n",
    "\n",
    "# spatial grid\n",
    "N = 400\n",
    "L = 1\n",
    "dx = L / N\n",
    "x = torch.arange(0.5 * dx, L + 0.5 * dx, dx)\n",
    "\n",
    "Tini =  vmap(lambda cas:(1 + 0.1 * torch.sin(2 * math.pi * x+torch.sin(cas)))*(1+torch.sin(cas)))(torch.tensor([1,2,3,4]))\n",
    "sigma = vmap(lambda cas:(1 + 0.1 * torch.sin(2 * math.pi * x+torch.sin(cas+1)))*(1+torch.sin(cas)))(torch.tensor([1,2,3,4]))\n",
    "    \n",
    "def solve(Tini,sigma):\n",
    "    CFL = 0.8\n",
    "    dt = CFL * dx  # time step\n",
    "    dtc = dt * c\n",
    "    ddtc = 1 / dtc\n",
    "\n",
    "    datarecord_sigma=sigma.clone()[None,:]\n",
    "    \n",
    "    # velocity grid & angle\n",
    "    Nvx = 8\n",
    "    mu, wmu = get_gauss_point(Nvx)\n",
    "\n",
    "    # distribution function\n",
    "    T = Tini\n",
    "    I = 0.5 * a * c * Tini**4\n",
    "    I = I.repeat(Nvx, 1)\n",
    "    I = F.pad(I[None, ...], (1, 1), mode='circular')[0]\n",
    "    I0 = wmu @ I  # energe\n",
    "    sigma = sigma.repeat(Nvx // 2, 1)\n",
    "\n",
    "    t=1.0\n",
    "    Nt=int(t / dt)\n",
    "    list_T=[]\n",
    "    list_E=[]\n",
    "    for loop in range(Nt):  #=1: 1/dt\n",
    "        I_out = I.clone()\n",
    "        T_out = T.clone()\n",
    "        I0_out = I0.clone()\n",
    "\n",
    "        index = slice(1, -1)\n",
    "        index_add1 = slice(2, None)\n",
    "        index_sub1 = slice(None, -2)\n",
    "\n",
    "        # streaming, positive vx\n",
    "        lv = slice(Nvx // 2, None)\n",
    "        coe = mu[lv]\n",
    "        I[lv, index] = I_out[lv, index] - dt / dx * coe[..., None] * (\n",
    "            I_out[lv, index] - I_out[lv, index_sub1]) + dt * sigma * (\n",
    "                (0.5 * a * c * T_out**4).repeat(Nvx // 2, 1) - I_out[lv, index])\n",
    "        \n",
    "        # streaming, negative vx\n",
    "        lv = slice(0, Nvx // 2)\n",
    "        coe = mu[lv]\n",
    "        I[lv, index] = I_out[lv, index] - dt / dx * coe[..., None] * (\n",
    "            I_out[lv, index_add1] - I_out[lv, index]) + dt * sigma * (\n",
    "                (0.5 * a * c * T_out**4).repeat(Nvx // 2, 1) - I_out[lv, index])\n",
    "\n",
    "        I = F.pad(I[None, ..., 1:-1], (1, 1), mode='circular')[0]\n",
    "        T = T_out + dt / cv * sigma[0, :] * (I0_out[index] - a * c * T_out**4)\n",
    "        I0 = wmu @ I\n",
    "\n",
    "        if loop%10==0:\n",
    "            list_E.append(I0[...,1:-1].clone())\n",
    "            list_T.append(T.clone())\n",
    "    datarecord_E=torch.stack(list_E,dim=0)\n",
    "    datarecord_T=torch.stack(list_T,dim=0)\n",
    "    return datarecord_E,datarecord_T,datarecord_sigma\n",
    "\n",
    "E,T,sigma=vmap(solve)(Tini,sigma)\n",
    "print(E.shape,T.shape,sigma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªåŠ¨æ±‚å¯¼\n",
    "\n",
    "æœ€ç®€å•çš„å°±æ˜¯ä½¿ç”¨gradæ±‚å‡½æ•°å¯¼æ•°ï¼Œå®ƒå‡è®¾å‡½æ•°è¿”å›çš„æ˜¯ä¸€ä¸ªå€¼ï¼Œç„¶åæ±‚è¿™ä¸ªå€¼å¯¹äºè¾“å…¥çš„å¯¼æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.132848Z",
     "start_time": "2023-04-14T07:33:51.126517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9999), tensor(0.9999))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9999), tensor(0.9999))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.func import grad\n",
    "x = torch.randn([]) #å¯ä»¥è¯•è¯•æ”¹å½¢çŠ¶ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
    "fx = lambda x: torch.sin(x)\n",
    "cos_x = grad(fx)(x)\n",
    "\n",
    "torch.cos(x),cos_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœè¾“å‡ºçš„ä¸æ˜¯ä¸€ä¸ªå€¼ï¼Œé‚£ä¹ˆgradæ–¹æ³•å°±ä¸å†èµ·ä½œç”¨äº†ã€‚è¿™æ—¶ï¼Œæ ¹æ®æˆ‘ä»¬æƒ³è¦çš„å¯¼æ•°ä¸åŒï¼Œæœ‰å¤šç§ä¸åŒçš„åšæ³•ã€‚ä¾‹å¦‚å¯¹äºsinè¿™ä¸ªä¾‹å­ï¼Œå‡è®¾è¾“å…¥çš„æ˜¯ä¸€ä¸ªå‘é‡ï¼Œæˆ‘ä»¬å…¶å®åªæƒ³æ±‚è¾“å‡ºçš„æ¯ä¸ªå€¼å¯¹åº”è¾“å…¥çš„æ¯ä¸ªå€¼çš„å¯¼ï¼Œå°±å¯ä»¥ç”¨vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.150944Z",
     "start_time": "2023-04-14T07:33:51.134537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]),\n",
       " tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]),\n",
       " tensor([ 0.3396,  0.8663,  0.8830,  0.7084,  0.9351, -0.1285, -0.0045,  0.8071,\n",
       "         -0.1174,  0.9670]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([10,]) #å¯ä»¥è¯•è¯•æ”¹å½¢çŠ¶ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
    "fx=lambda x: torch.sin(x)\n",
    "cos_x = vmap(grad(fx))(x) #gradå‡½æ•°è¢«å‘é‡åŒ–åˆ°äº†ä¸€ä¸ªvectorä¸Š\n",
    "\n",
    "torch.cos(x),cos_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿˜æœ‰ä¸€ç§æƒ…å†µï¼Œå°±æ˜¯æˆ‘ä»¬æƒ³è¦æ±‚çš„å°±æ˜¯è¾“å‡ºçš„æ¯ä¸ªå€¼å¯¹è¾“å…¥çš„æ¯ä¸ªå€¼çš„å¯¼æ•°ï¼Œæ­¤æ—¶æˆ‘ä»¬ç›¸æ±‚çš„æ˜¯jacobiançŸ©é˜µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.165143Z",
     "start_time": "2023-04-14T07:33:51.153503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([10]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9992,  0.7487,  0.9434,  0.9032,  0.9164,  0.6165,  0.5111,  1.0000,\n",
       "          0.7079, -0.1347]),\n",
       " tensor([[ 0.9992,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.7487,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.9434,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.9032,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9164,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6165,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5111,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.7079, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.1347]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([10]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9992,  0.7487,  0.9434,  0.9032,  0.9164,  0.6165,  0.5111,  1.0000,\n",
       "          0.7079, -0.1347]),\n",
       " tensor([[ 0.9992,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.7487,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.9434,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.9032,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9164,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6165,  0.0000,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5111,  0.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.7079, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -0.1347]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.func import jacrev,jacfwd,hessian\n",
    "\n",
    "x = torch.randn([10,]) #å¯ä»¥è¯•è¯•æ”¹å½¢çŠ¶ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
    "fx=lambda x: torch.sin(x)\n",
    "cos_x = jacrev(fx)(x) #gradå‡½æ•°è¢«å‘é‡åŒ–åˆ°äº†ä¸€ä¸ªvectorä¸Š\n",
    "\n",
    "print(cos_x.shape,x.shape,fx(x).shape)\n",
    "torch.cos(x),cos_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.199268Z",
     "start_time": "2023-04-14T07:33:51.167656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 10, 2, 10, 2]) torch.Size([10, 2])\n",
      "torch.Size([10, 2, 10, 2, 10, 2]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.func import jacrev,jacfwd,hessian\n",
    "\n",
    "x = torch.randn([10,2]) #å¯ä»¥è¯•è¯•æ”¹å½¢çŠ¶ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
    "fx=lambda x: torch.sin(x)\n",
    "hessian_x = hessian(fx)(x) #gradå‡½æ•°è¢«å‘é‡åŒ–åˆ°äº†ä¸€ä¸ªvectorä¸Š\n",
    "\n",
    "print(hessian_x.shape,x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ›´ä¸ºå¸¸è§çš„æƒ…å†µæ˜¯ä»¥ä¸Šä¸¤ç§çš„æ··åˆï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œå»æ‹ŸåˆäºŒç»´çš„Euleræ–¹ç¨‹çš„è§£ï¼Œè¿™ä¸ªç½‘ç»œæ˜¯ä»å‘é‡åˆ°å‘é‡çš„ä¸€ä¸ªæ˜ å°„ï¼Œæˆ‘ä»¬å¸Œæœ›è®¡ç®—å¾—åˆ°$\\frac{\\partial f}{\\partial (x,t)}$è¿™æ ·ä¸€ä¸ªæœ‰6ä¸ªå…ƒç´ çš„jacobianã€‚åŒæ—¶æˆ‘ä»¬ç½‘ç»œçš„è¾“å…¥æ˜¯batchsize=1000ï¼Œæˆ‘ä»¬å°±è¦åŒæ—¶è®¡ç®—è¿™1000ä¸ªsampleçš„jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T07:33:51.262010Z",
     "start_time": "2023-04-14T07:33:51.201449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([1000, 2]),y.shape=torch.Size([1000, 3]),y2.shape=torch.Size([1000, 3])\n",
      "dy_dx_1.shape=torch.Size([1000, 3, 2]),dy_dx_2.shape=torch.Size([1000, 3, 2])\n",
      "ddy_dxx.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx2.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx3.shape=torch.Size([1000, 3, 2, 2])\n",
      "x.shape=torch.Size([1000, 2]),y.shape=torch.Size([1000, 3]),y2.shape=torch.Size([1000, 3])\n",
      "dy_dx_1.shape=torch.Size([1000, 3, 2]),dy_dx_2.shape=torch.Size([1000, 3, 2])\n",
      "ddy_dxx.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx2.shape=torch.Size([1000, 3, 2, 2]),ddy_dxx3.shape=torch.Size([1000, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn([1000,2])\n",
    "Net=torch.nn.Linear(2,3)\n",
    "y=Net(x)\n",
    "y2=vmap(Net)(x)\n",
    "print(f\"{x.shape=},{y.shape=},{y2.shape=}\")\n",
    "\n",
    "dy_dx_1=vmap(jacrev(Net))(x)\n",
    "dy_dx_2=vmap(jacfwd(Net))(x)\n",
    "print(f\"{dy_dx_1.shape=},{dy_dx_2.shape=}\")\n",
    "\n",
    "def myhessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "def myhessian2(f):\n",
    "    return jacrev(jacfwd(f))\n",
    "\n",
    "ddy_dxx=vmap(hessian(Net))(x)\n",
    "ddy_dxx2=vmap(myhessian(Net))(x)\n",
    "ddy_dxx3=vmap(myhessian2(Net))(x)\n",
    "\n",
    "print(f\"{ddy_dxx.shape=},{ddy_dxx2.shape=},{ddy_dxx3.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¦‚ä½•é€‰æ‹©jacrevä¸jacfwd\n",
    "\n",
    "\n",
    "jacrevä¸jacfwd\n",
    "> These two functions compute the same values (up to machine numerics), but differ in their implementation: jacfwd uses forward-mode automatic differentiation, which is more efficient for â€œtallâ€ Jacobian matrices, while jacrev uses reverse-mode, which is more efficient for â€œwideâ€ Jacobian matrices. For matrices that are near-square, jacfwd probably has an edge over jacrev.\n",
    "\n",
    "ä»¥åŠå¯¹äºhessian\n",
    "\n",
    "> To implement hessian, we could have used jacfwd(jacrev(f)) or jacrev(jacfwd(f)) or any other composition of the two. But forward-over-reverse is typically the most efficient. Thatâ€™s because in the inner Jacobian computation weâ€™re often differentiating a function wide Jacobian (maybe like a loss function ğ‘“:â„â¿â†’â„), while in the outer Jacobian computation weâ€™re differentiating a function with a square Jacobian (since âˆ‡ğ‘“:â„â¿â†’â„â¿), which is where forward-mode wins out.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
