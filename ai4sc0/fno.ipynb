{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier neural operator\n",
    "\n",
    "[项目主页](https://zongyi-li.github.io/blog/2020/fourier-pde/)\n",
    "\n",
    "[代码仓库](https://github.com/neuraloperator/neuraloperator)\n",
    "\n",
    "## 网络结构\n",
    "\n",
    "![](https://content.lz1.fun/202304112137340.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T13:40:55.559572Z",
     "start_time": "2023-04-11T13:40:53.979002Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们首先定义FNO中的单个block，也就是上图中的黄框部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T13:54:48.898306Z",
     "start_time": "2023-04-11T13:54:48.871751Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#  1d fourier layer\n",
    "################################################################\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes = modes  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.scale = 1 / (in_channels * out_channels)\n",
    "        self.weights = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes, dtype=torch.cfloat)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft(x, dim=-1, norm=\"ortho\")\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        out_ft = torch.zeros(\n",
    "            x.shape[0], self.in_channels, x.size(-1) + 1, device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, : self.modes] =  torch.einsum(\"bix,iox->box\",x_ft[:, :, : self.modes],self.weights)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, dim=-1, n=x.size(-1), norm=\"ortho\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后一个完成FNO的一个block，这有若干个Fourier卷积和普通卷积组合而成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBlock1d(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, modes, width, padding_mode, activation):\n",
    "        super(SimpleBlock1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input shape: (batchsize, x=s, c=2)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "        self.inchannel = inchannel\n",
    "        self.outchannel = outchannel\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "        self.fc0 = nn.Linear(\n",
    "            self.inchannel, self.width\n",
    "        )  # input channel is 2: (a(x), x)\n",
    "\n",
    "        self.conv0 = SpectralConv1d(self.width, self.width, self.modes)\n",
    "        self.conv1 = SpectralConv1d(self.width, self.width, self.modes)\n",
    "        self.conv2 = SpectralConv1d(self.width, self.width, self.modes)\n",
    "        self.conv3 = SpectralConv1d(self.width, self.width, self.modes)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, self.outchannel)\n",
    "\n",
    "        self.act=getattr(torch.nn, activation)()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = self.act(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = self.act(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = self.act(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，一个FNO由若干个FNO块组成，我们这里选取最简单的由单块组成的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=5,\n",
    "        out_channel=1,\n",
    "        modes=32,\n",
    "        hidden=64,\n",
    "        padding_mode=\"circular\",\n",
    "        activation=\"ReLU\",\n",
    "    ):\n",
    "        super(FNO1d, self).__init__()\n",
    "        self.conv1 = SimpleBlock1d(\n",
    "            in_channel,\n",
    "            out_channel,\n",
    "            modes,\n",
    "            width=hidden,\n",
    "            padding_mode=padding_mode,\n",
    "            activation=activation,\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T13:54:49.317095Z",
     "start_time": "2023-04-11T13:54:49.277326Z"
    }
   },
   "source": [
    "至此，我们已经完成了FNO网络结构的定义。下面就是找一些数据来测试FNO的效果。我们使用之前写好的RTE求解器生成100组数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T13:54:49.577172Z",
     "start_time": "2023-04-11T13:54:49.548229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 50, 400]) torch.Size([100, 50, 400]) torch.Size([100, 1, 400])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from torch.func import vmap\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_gauss_point(n):\n",
    "    x, w = np.polynomial.legendre.leggauss(n)\n",
    "    return torch.from_numpy(x).to(dtype=torch.get_default_dtype()), torch.from_numpy(w).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "a = 1\n",
    "c = 1\n",
    "rho = 1\n",
    "cv = 1\n",
    "\n",
    "# spatial grid\n",
    "N = 400\n",
    "L = 1\n",
    "dx = L / N\n",
    "x = torch.arange(0.5 * dx, L + 0.5 * dx, dx)\n",
    "\n",
    "Tini =  vmap(lambda cas:(1 + 0.1 * torch.sin(2 * math.pi * x * (1+cas%2) +torch.sin(cas)))*(1+torch.sin(cas)))(torch.arange(100))\n",
    "sigma = vmap(lambda cas:(1 + 0.1 * torch.sin(2 * math.pi * x * (1+cas%2)  +torch.sin(cas+1)))*(1+torch.sin(cas)))(torch.arange(100))\n",
    "    \n",
    "def solve(Tini,sigma):\n",
    "    CFL = 0.8\n",
    "    dt = CFL * dx  # time step\n",
    "    dtc = dt * c\n",
    "    ddtc = 1 / dtc\n",
    "\n",
    "    datarecord_sigma=sigma.clone()[None,:]\n",
    "    \n",
    "    # velocity grid & angle\n",
    "    Nvx = 8\n",
    "    mu, wmu = get_gauss_point(Nvx)\n",
    "\n",
    "    # distribution function\n",
    "    T = Tini\n",
    "    I = 0.5 * a * c * Tini**4\n",
    "    I = I.repeat(Nvx, 1)\n",
    "    I = F.pad(I[None, ...], (1, 1), mode='circular')[0]\n",
    "    I0 = wmu @ I  # energe\n",
    "    sigma = sigma.repeat(Nvx // 2, 1)\n",
    "\n",
    "    t=1.0\n",
    "    Nt=int(t / dt)\n",
    "    list_T=[]\n",
    "    list_E=[]\n",
    "    for loop in range(Nt):  #=1: 1/dt\n",
    "        I_out = I.clone()\n",
    "        T_out = T.clone()\n",
    "        I0_out = I0.clone()\n",
    "\n",
    "        index = slice(1, -1)\n",
    "        index_add1 = slice(2, None)\n",
    "        index_sub1 = slice(None, -2)\n",
    "\n",
    "        # streaming, positive vx\n",
    "        lv = slice(Nvx // 2, None)\n",
    "        coe = mu[lv]\n",
    "        I[lv, index] = I_out[lv, index] - dt / dx * coe[..., None] * (\n",
    "            I_out[lv, index] - I_out[lv, index_sub1]) + dt * sigma * (\n",
    "                (0.5 * a * c * T_out**4).repeat(Nvx // 2, 1) - I_out[lv, index])\n",
    "        \n",
    "        # streaming, negative vx\n",
    "        lv = slice(0, Nvx // 2)\n",
    "        coe = mu[lv]\n",
    "        I[lv, index] = I_out[lv, index] - dt / dx * coe[..., None] * (\n",
    "            I_out[lv, index_add1] - I_out[lv, index]) + dt * sigma * (\n",
    "                (0.5 * a * c * T_out**4).repeat(Nvx // 2, 1) - I_out[lv, index])\n",
    "\n",
    "        I = F.pad(I[None, ..., 1:-1], (1, 1), mode='circular')[0]\n",
    "        T = T_out + dt / cv * sigma[0, :] * (I0_out[index] - a * c * T_out**4)\n",
    "        I0 = wmu @ I\n",
    "\n",
    "        if loop%10==0:\n",
    "            list_E.append(I0[...,1:-1].clone())\n",
    "            list_T.append(T.clone())\n",
    "    datarecord_E=torch.stack(list_E,dim=0)\n",
    "    datarecord_T=torch.stack(list_T,dim=0)\n",
    "    return datarecord_E,datarecord_T,datarecord_sigma\n",
    "\n",
    "E,T,sigma=vmap(solve)(Tini,sigma)\n",
    "print(E.shape,T.shape,sigma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们将其包装成数据集，我们令输入是0时刻的E,T以及参数sigma，输出的是结束时刻的E和T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape=torch.Size([100, 400, 3]),y_data.shape=torch.Size([100, 400, 2])\n"
     ]
    }
   ],
   "source": [
    "x_data=torch.stack([E[:,0],T[:,0],sigma.expand_as(E)[:,0]],dim=-1)\n",
    "y_data=torch.stack([E[:,-1],T[:,-1]],dim=-1)\n",
    "print(f\"{x_data.shape=},{y_data.shape=}\")\n",
    "\n",
    "x_train,y_train=x_data[:80],y_data[:80]\n",
    "x_valid,y_valid=x_data[80:],y_data[80:]\n",
    "\n",
    "train_dataset=torch.utils.data.TensorDataset(x_train,y_train)\n",
    "valid_dataset=torch.utils.data.TensorDataset(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T13:55:22.150889Z",
     "start_time": "2023-04-11T13:55:22.147076Z"
    }
   },
   "source": [
    "## 训练网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataloader\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m valid_dataloader\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(valid_dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m myFNO\u001b[38;5;241m=\u001b[39mFNO1d(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=2)\n",
    "valid_dataloader=torch.utils.data.DataLoader(valid_dataset,batch_size=64,shuffle=False,num_workers=2)\n",
    "\n",
    "myFNO=FNO1d(3,2)\n",
    "myFNO.cuda()\n",
    "optimizer=torch.optim.Adam(myFNO.parameters(), lr=1e-3)\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,100,2)\n",
    "epochs=300\n",
    "\n",
    "train_loss_hist=[]\n",
    "valid_loss_hist=[]\n",
    "for i in range(1,1+epochs):\n",
    "    train_loss=0\n",
    "    for x,y in train_dataloader:\n",
    "        x,y=x.cuda(),y.cuda()\n",
    "        y_pred=myFNO(x)\n",
    "        loss=(y_pred-y).square().mean()\n",
    "        train_loss+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss_hist.append(train_loss/80)   \n",
    "    scheduler.step()\n",
    "    \n",
    "    valid_loss=0\n",
    "    for x,y in valid_dataloader:\n",
    "        x,y=x.cuda(),y.cuda()\n",
    "        y_pred=myFNO(x)\n",
    "        loss=(y_pred-y).square().mean()\n",
    "        valid_loss+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    valid_loss_hist.append(valid_loss/20)  \n",
    "        \n",
    "    if i%10==0:\n",
    "        print(f\"epoch:{i}, train loss: {train_loss}, valid loss: {valid_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred=myFNO(x_valid)\n",
    "\n",
    "plt.plot(y_valid[2,:,0],\"--\")\n",
    "plt.plot(y_pred[2,:,0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch20",
   "language": "python",
   "name": "pytorch20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
